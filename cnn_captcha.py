# -*- coding: utf-8 -*-
"""CNN-Captcha

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PGY7fWDkfFRNYKr3rmVyLelTn5LTTUro

# **Loads CAPTCHA images**
"""

import os
from google.colab import drive

# Mount to google drive
drive.mount('/content/drive', force_remount=True)

# Folder path for captcha dataset
folder_path = '/content/drive/MyDrive/CAPTCHA_3000'
#folder_path = '/content/drive/MyDrive/Main'
#folder_path = '/content/drive/MyDrive/CAPTCHA Database'

jpg_files = []

try:
    # Go through all directories and files in folder_path
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith('.jpg'):  # Find all .jpg files in folder
                jpg_files.append(os.path.join(root, file))

    # Now jpg_files contains all the paths to the .jpg files
    # Prints out how many .jpg files have been loaded
    print(f"Found {len(jpg_files)} .jpg files.")

except Exception as e:
    print(f"An error occurred: {e}")

"""# **Creates CNN Model**"""

from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

def build_cnn_model(input_shape, num_classes, num_chars):
    # Input shape should be the shape of the CAPTCHA images, e.g., (40, 150, 3)
    # Num_classes is the number of possible characters for each position in the CAPTCHA
    # Num_chars is the length of the CAPTCHA strings

    model = models.Sequential()

    # CNN layers for feature extraction
    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

    # Flatten the CNN output to feed into the dense layers
    model.add(layers.Flatten())

    # Dense layer for further processing
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dropout(0.5))

    # Output layer, one set of classes for each character in the CAPTCHA
    model.add(layers.Dense(num_chars * num_classes, activation='softmax'))

    # Reshape the output layer to have the shape (num_chars, num_classes)
    model.add(layers.Reshape((num_chars, num_classes)))

    return model

# Define input shape, number of classes, and length of CAPTCHA
input_shape = (40, 150, 3)  # Adjust as per your CAPTCHA image dimensions
num_classes = 62  # Total number of possible characters (0-9, a-z, A-Z)
num_chars = 5  # The length of CAPTCHA codes

# Adjust the learning rate
lr = 1e-4
optimizer = Adam(learning_rate=lr, clipvalue=0.5)  # Adding gradient clipping

# Build and compile the model
model = build_cnn_model(input_shape, num_classes, num_chars)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""# **Preprocesses Data**"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import cv2
import os

# Preprocessing images and labels
def preprocess_image(image_path):
    # Load image
    image = cv2.imread(image_path)

    # Check if the image has been loaded correctly
    if image is None:
        raise ValueError(f"Unable to load image at {image_path}. Please check the file path and access permissions.")

    # If image is loaded, convert color scheme and normalize pixel values
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = image / 255.0  # Normalize to 0-1 range
    return image

# Character Index Mapping
import string

# Create a mapping of characters to integers
characters = string.digits + string.ascii_lowercase + string.ascii_uppercase
char_to_index = {char: index for index, char in enumerate(characters)}
index_to_char = {index: char for char, index in char_to_index.items()}



def encode_label(label):
    # Initialize a matrix of zeros with shape (len(label), 62)
    encoded = np.zeros((len(label), 62))

    for i, char in enumerate(label):
        index = char_to_index[char]  # Get the index for this character
        encoded[i, index] = 1  # Set the appropriate element to 1

    return encoded


# Load and preprocess the dataset
images = []
labels = []
count = 0
total_files = len(os.listdir(folder_path))  # Get the total number of files to process

for filename in os.listdir(folder_path):
    if filename.endswith('.jpg'):
        try:
            label = filename.split('.')[0]  # This is a simplification
            image_path = os.path.join(folder_path, filename)
            image = preprocess_image(image_path)

            images.append(image)
            labels.append(encode_label(label))
            count += 1

            # Print progress every 100 images
            if count % 100 == 0:
                print(f"Processed {count}/{total_files} images.")
        except Exception as e:
            print(f"Failed to process image {filename}: {e}")

# Now 'images' and 'labels' are populated with preprocessed data
print(f"Finished processing all images. Total processed images: {count}")

images = np.array(images)
labels = np.array(labels)

"""# **Split data**"""

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2

"""# **Train**"""

# Train your model
model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))

"""# **Test**"""

# After training, evaluate model on the testing set
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')

"""# **Pick random CAPTCHA image from testing set and make prections**"""

import matplotlib.pyplot as plt
import numpy as np

# Choose a random image from the training set
random_index = np.random.randint(0, len(X_test))
random_image = X_test[random_index]
random_label = y_test[random_index]

# Display the chosen image
plt.imshow(random_image)
plt.axis('off')  # Turn off axis numbers and ticks
plt.show()

# Reshape the image to match the model's input format
random_image = np.expand_dims(random_image, axis=0)

# Predict the characters in the image
prediction = model.predict(random_image)

# Decode the prediction
predicted_label = [index_to_char[np.argmax(char)] for char in prediction[0]]

# Convert the one-hot encoded true label to characters
true_label = [index_to_char[np.argmax(char)] for char in random_label]

print(f"Predicted characters: {''.join(predicted_label)}")
print(f"True characters: {''.join(true_label)}")